{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angelaestefan/concentracion/blob/master/actividad_curvas_aprendizaje_validacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aba961de",
      "metadata": {
        "id": "aba961de"
      },
      "source": [
        "# Actividad evaluación de modelos\n",
        "\n",
        "Evaluar un modelo de machine learning es un proceso fundamental. En particular, analizar el grado de sesgo y varianza resulta esencial para comprender su desempeño y capacidad de generalización.\n",
        "\n",
        "En este cuaderno trabajaremos con el dataset Diabetes disponible en scikit-learn, sobre el cual ajustaremos diferentes modelos de regresión. Posteriormente, construiremos curvas de aprendizaje y de validación con el fin de obtener información sobre el nivel de sesgo y varianza presente en cada modelo.\n",
        "\n",
        "Además, se te pedirá responder algunas preguntas y completar fragmentos de código, lo que permitirá reforzar los conceptos vistos y consolidar tu comprensión del proceso de evaluación de modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "075a2f86",
      "metadata": {
        "id": "075a2f86"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "En este dataset vamos a utilizar el dataset sintético Diabetes.\n",
        "\n",
        "https://www.geeksforgeeks.org/machine-learning/sklearn-diabetes-dataset/\n",
        "\n",
        "Diabetes dataset\n",
        "- 442 muestras (filas)\n",
        "- 10 caracteristicas (columnas)\n",
        "\n",
        "Características:\n",
        "- age – Edad del paciente.\n",
        "- sex – Sexo del paciente.\n",
        "- bmi – Índice de masa corporal (body mass index).\n",
        "- bp – Presión arterial promedio.\n",
        "- s1 – Medida de colesterol sérico.\n",
        "- s2 – LDL (lipoproteínas de baja densidad).\n",
        "- s3 – HDL (lipoproteínas de alta densidad).\n",
        "- s4 – Relación de colesterol total con HDL.\n",
        "- s5 – Nivel de triglicéridos en sangre.\n",
        "- s6 – Nivel de glucosa en sangre.\n",
        "\n",
        "Variable objetivo:\n",
        "\n",
        "Una medida cuantitativa de la progresión de la diabetes un año después de la primera observación."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "130f1d06",
      "metadata": {
        "id": "130f1d06"
      },
      "source": [
        "### SGDRegressor\n",
        "\n",
        "Como un primer ejemplo, vamos a crear una curva de aprendizaje para un Regresor de la clase SGDRegressor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8b5e7c6",
      "metadata": {
        "id": "c8b5e7c6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import learning_curve, cross_val_score\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Datos\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# Verificamos mean y std de cada característica\n",
        "print(\"Media por característica:\")\n",
        "print(np.mean(X, axis=0))\n",
        "print(\"\\nDesviación estándar por característica:\")\n",
        "print(np.std(X, axis=0))\n",
        "\n",
        "\n",
        "# Modelo real (pipeline con escalado + SGD)\n",
        "model = make_pipeline(\n",
        "    StandardScaler(),             # Para que la desviación estandar sea de 1\n",
        "    SGDRegressor(\n",
        "        loss=\"squared_error\",     # equivalente a MSE\n",
        "        learning_rate=\"constant\",\n",
        "        eta0=1e-3,                # tasa de aprendizaje inicial\n",
        "        max_iter=2000,            # más iteraciones para asegurar convergencia\n",
        "        tol=1e-3,\n",
        "        random_state=42,\n",
        "    )\n",
        ")\n",
        "\n",
        "# Curva de aprendizaje del modelo\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    model, X, y, cv=5, scoring=\"neg_mean_squared_error\",\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1\n",
        ")\n",
        "\n",
        "# Medias y desviaciones\n",
        "train_mean = -np.mean(train_scores, axis=1)\n",
        "train_std  = np.std(train_scores, axis=1)\n",
        "val_mean   = -np.mean(val_scores, axis=1)\n",
        "val_std    = np.std(val_scores, axis=1)\n",
        "\n",
        "# ======== Baselines ========\n",
        "\n",
        "# DummyRegressor con media\n",
        "dummy_mean = DummyRegressor(strategy=\"mean\")\n",
        "dummy_mean_scores = cross_val_score(dummy_mean, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "baseline_mean = -np.mean(dummy_mean_scores)\n",
        "\n",
        "# DummyRegressor con mediana\n",
        "dummy_median = DummyRegressor(strategy=\"median\")\n",
        "dummy_median_scores = cross_val_score(dummy_median, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "baseline_median = -np.mean(dummy_median_scores)\n",
        "\n",
        "# ======== Gráfica ========\n",
        "\n",
        "plt.plot(train_sizes, train_mean, label=\"Entrenamiento (SGDRegressor)\", color=\"blue\")\n",
        "plt.fill_between(train_sizes, train_mean-train_std, train_mean+train_std, alpha=0.2, color=\"blue\")\n",
        "\n",
        "plt.plot(train_sizes, val_mean, label=\"Validación (SGDRegressor)\", color=\"orange\")\n",
        "plt.fill_between(train_sizes, val_mean-val_std, val_mean+val_std, alpha=0.2, color=\"orange\")\n",
        "\n",
        "# Líneas horizontales de los baselines\n",
        "plt.axhline(y=baseline_mean, color=\"red\", linestyle=\"--\", label=\"Dummy (mean)\")\n",
        "plt.axhline(y=baseline_median, color=\"green\", linestyle=\"--\", label=\"Dummy (median)\")\n",
        "\n",
        "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Curva de aprendizaje con SGDRegressor y baselines\")\n",
        "plt.ylim(0, 7000)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcd07db4",
      "metadata": {
        "id": "bcd07db4"
      },
      "source": [
        "Edita esta celda para dar respuesta a las siguientes preguntas:\n",
        "\n",
        "1. ¿Por qué utilizamos validación cruzada para generar la curva de aprendizaje?\n",
        "2. ¿El desempeño del modelo con estos parámetros se beneficiaría si aumentamos el número de ejemplos de entrenamiento?\n",
        "3. ¿Qué grado de sesgo presenta el modelo al inicio y al final del entrenamiento?\n",
        "4. ¿Qué grado de varianza presenta el modelo al inicio y al final del entrenamiento?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ccbf11c",
      "metadata": {
        "id": "7ccbf11c"
      },
      "source": [
        "### Regresión polinomial\n",
        "\n",
        "Modifica el código anterior para incluir términos de segundo orden y las interacciones entre las variables (features). Puedes copiar el código de la celda anterior y modificar únicamente la parte necesaria. De esta forma podrás comparar ambas gráficas.\n",
        "\n",
        "Para ello, puedes utilizar la función PolynomialFeatures disponible en sklearn.preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "061093ff",
      "metadata": {
        "id": "061093ff"
      },
      "outputs": [],
      "source": [
        "# Tu código aquí"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4940f31b",
      "metadata": {
        "id": "4940f31b"
      },
      "source": [
        "Contesta las siguientes preguntas:\n",
        "\n",
        "1. ¿Mejoró el desempeño del modelo?.\n",
        "2. ¿Qué grado de sesgo presenta el modelo al inicio y al final del entrenamiento?\n",
        "4. ¿Qué grado de varianza presenta el modelo al inicio y al final del entrenamiento?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9054afaa",
      "metadata": {
        "id": "9054afaa"
      },
      "source": [
        "#### Regularización\n",
        "\n",
        "Para demostrar cómo la regularización afecta el grado de sesgo y varianza, agrega regularización al SGDRegressor de la siguiente celda. Te recomiendo comenzar probando con regularización tipo Ridge. Consulta la documentación de la clase SGDRegressor para obtener información sobre los argumentos penalty y alpha, que te permitirán definir el tipo de regularización y la intensidad de la misma.\n",
        "\n",
        "Prueba con distintos valores de alpha. Por ejemplo, utiliza regularización L2 (penalty=\"l2\") y experimenta con valores de alpha como 0.1, 1, 10 y 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4f1c77f",
      "metadata": {
        "id": "c4f1c77f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import learning_curve, cross_val_score\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Datos\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# ===== Modelo con polinomios + Ridge regularization =====\n",
        "model_poly = make_pipeline(\n",
        "    PolynomialFeatures(degree=2, include_bias=True),\n",
        "    StandardScaler(),\n",
        "    SGDRegressor(\n",
        "        loss=\"squared_error\",\n",
        "        learning_rate=\"constant\",\n",
        "        eta0=1e-3,\n",
        "        max_iter=2000,\n",
        "        tol=1e-3,\n",
        "        random_state=42,\n",
        "        # Agrega aqui regularización Ridge\n",
        "    )\n",
        ")\n",
        "\n",
        "# Curva de aprendizaje con polinomios\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    model_poly, X, y, cv=5, scoring=\"neg_mean_squared_error\",\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1\n",
        ")\n",
        "\n",
        "# Medias y desviaciones\n",
        "train_mean = -np.mean(train_scores, axis=1)\n",
        "train_std  = np.std(train_scores, axis=1)\n",
        "val_mean   = -np.mean(val_scores, axis=1)\n",
        "val_std    = np.std(val_scores, axis=1)\n",
        "\n",
        "# ======== Baselines ========\n",
        "dummy_mean = DummyRegressor(strategy=\"mean\")\n",
        "dummy_mean_scores = cross_val_score(dummy_mean, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "baseline_mean = -np.mean(dummy_mean_scores)\n",
        "\n",
        "dummy_median = DummyRegressor(strategy=\"median\")\n",
        "dummy_median_scores = cross_val_score(dummy_median, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "baseline_median = -np.mean(dummy_median_scores)\n",
        "\n",
        "# ======== Gráfica ========\n",
        "plt.plot(train_sizes, train_mean, label=\"Entrenamiento (SGD + Poly + Ridge)\", color=\"blue\")\n",
        "plt.fill_between(train_sizes, train_mean-train_std, train_mean+train_std, alpha=0.2, color=\"blue\")\n",
        "\n",
        "plt.plot(train_sizes, val_mean, label=\"Validación (SGD + Poly + Ridge)\", color=\"orange\")\n",
        "plt.fill_between(train_sizes, val_mean-val_std, val_mean+val_std, alpha=0.2, color=\"orange\")\n",
        "\n",
        "plt.axhline(y=baseline_mean, color=\"red\", linestyle=\"--\", label=\"Dummy (mean)\")\n",
        "plt.axhline(y=baseline_median, color=\"green\", linestyle=\"--\", label=\"Dummy (median)\")\n",
        "\n",
        "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Curva de aprendizaje con Ridge (SGDRegressor)\")\n",
        "plt.ylim(0, 7000)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba313f01",
      "metadata": {
        "id": "ba313f01"
      },
      "source": [
        "Edita esta celda para contestar las siguientes preguntas:\n",
        "\n",
        "1. ¿Qué grado de sesgo (bias) y varianza observas con valores pequeños de alpha (por ejemplo, 0.1)?\n",
        "2. ¿Qué grado de sesgo (bias) y varianza observas con valores grandes de alpha (por ejemplo, 100)?\n",
        "3. ¿Cómo explicarías esta diferencia con tus propias palabras?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "600dd73f",
      "metadata": {
        "id": "600dd73f"
      },
      "source": [
        "### Regresión con K-Vecinos más cercanos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd678514",
      "metadata": {
        "id": "dd678514"
      },
      "source": [
        "1. Reemplaza la clase SGDRegressor por KNeighborsRegressor. Comienza con los siguientes parámetros:\n",
        "\n",
        "- n_neighbors=5,     \n",
        "- weights=\"uniform\",\n",
        "- metric=\"minkowski\",\n",
        "- p=2\n",
        "\n",
        "2. Consulta en la documentación la función de los parámetros weights y metric\n",
        "3. Genera la curva de validación correspondiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "278e75a6",
      "metadata": {
        "id": "278e75a6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import learning_curve, cross_val_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Datos\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# Modelo real (pipeline con escalado + KNN)\n",
        "model = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    # Define aqui tu instanciación de la clase KNeighborsRegressor\n",
        ")\n",
        "\n",
        "# Curva de aprendizaje del modelo\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    model, X, y, cv=5, scoring=\"neg_mean_squared_error\",\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1\n",
        ")\n",
        "\n",
        "# Medias y desviaciones\n",
        "train_mean = -np.mean(train_scores, axis=1)\n",
        "train_std  = np.std(train_scores, axis=1)\n",
        "val_mean   = -np.mean(val_scores, axis=1)\n",
        "val_std    = np.std(val_scores, axis=1)\n",
        "\n",
        "# ======== Baselines ========\n",
        "\n",
        "# DummyRegressor con media\n",
        "dummy_mean = DummyRegressor(strategy=\"mean\")\n",
        "dummy_mean_scores = cross_val_score(dummy_mean, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "baseline_mean = -np.mean(dummy_mean_scores)\n",
        "\n",
        "# DummyRegressor con mediana\n",
        "dummy_median = DummyRegressor(strategy=\"median\")\n",
        "dummy_median_scores = cross_val_score(dummy_median, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "baseline_median = -np.mean(dummy_median_scores)\n",
        "\n",
        "# ======== Gráfica ========\n",
        "\n",
        "plt.plot(train_sizes, train_mean, label=\"Entrenamiento (KNN)\", color=\"blue\")\n",
        "plt.fill_between(train_sizes, train_mean-train_std, train_mean+train_std, alpha=0.2, color=\"blue\")\n",
        "\n",
        "plt.plot(train_sizes, val_mean, label=\"Validación (KNN)\", color=\"orange\")\n",
        "plt.fill_between(train_sizes, val_mean-val_std, val_mean+val_std, alpha=0.2, color=\"orange\")\n",
        "\n",
        "# Líneas horizontales de los baselines\n",
        "plt.axhline(y=baseline_mean, color=\"red\", linestyle=\"--\", label=\"Dummy (mean)\")\n",
        "plt.axhline(y=baseline_median, color=\"green\", linestyle=\"--\", label=\"Dummy (median)\")\n",
        "\n",
        "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Curva de aprendizaje con KNN y baselines\")\n",
        "plt.ylim(0, 7000)  # Ajustar el límite del eje y para mejor visualización\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "974bdb1d",
      "metadata": {
        "id": "974bdb1d"
      },
      "source": [
        "Edita esta celda y responde las siguientes preguntas:\n",
        "\n",
        "1. ¿Mejoró el desempeño del modelo en comparación con el modelo anterior (SGDRegressor)?\n",
        "2. ¿Qué grado de sesgo presenta el modelo al inicio y al final del entrenamiento?\n",
        "3. ¿Qué grado de varianza presenta el modelo al inicio y al final del entrenamiento?\n",
        "4. ¿Qué hiperparámetro consideras que deberíamos ajustar para intentar mejorar el modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab750b90",
      "metadata": {
        "id": "ab750b90"
      },
      "source": [
        "La siguiente celda crea una curva de validación en el que el eje horizontal muestra distintos valores del parametro k y el eje vertical el desempeño."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6c708e",
      "metadata": {
        "id": "ec6c708e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Datos\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# Modelo KNN dentro de un pipeline con escalado\n",
        "model = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    KNeighborsRegressor()\n",
        ")\n",
        "\n",
        "# Rango de vecinos a probar\n",
        "param_range = np.arange(1, 31)\n",
        "\n",
        "# Curva de validación\n",
        "metric = 'neg_mean_squared_error'  # métrica de evaluación\n",
        "train_scores, val_scores = validation_curve(\n",
        "    model, X, y,\n",
        "    param_name=\"kneighborsregressor__n_neighbors\",  # nombre completo en pipeline\n",
        "    param_range=param_range,\n",
        "    cv=5,\n",
        "    scoring=metric,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Convertir de MSE negativo a MSE positivo\n",
        "train_mean = -np.mean(train_scores, axis=1)\n",
        "train_std  = np.std(train_scores, axis=1)\n",
        "val_mean   = -np.mean(val_scores, axis=1)\n",
        "val_std    = np.std(val_scores, axis=1)\n",
        "\n",
        "# Gráfica\n",
        "plt.plot(param_range, train_mean, label=\"Entrenamiento\", color=\"blue\")\n",
        "plt.fill_between(param_range, train_mean-train_std, train_mean+train_std, alpha=0.2, color=\"blue\")\n",
        "\n",
        "plt.plot(param_range, val_mean, label=\"Validación\", color=\"orange\")\n",
        "plt.fill_between(param_range, val_mean-val_std, val_mean+val_std, alpha=0.2, color=\"orange\")\n",
        "\n",
        "plt.xlabel(\"Número de vecinos (k)\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Curva de validación - KNeighborsRegressor\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db840938",
      "metadata": {
        "id": "db840938"
      },
      "source": [
        "Contesta las siguientes preguntas:\n",
        "\n",
        "1. ¿Qué grado de sesgo y varianza se observa para valores pequeños de k?\n",
        "2. ¿Qué grado de sesgo y varianza se observa para valores grandes de k?\n",
        "3. ¿Qué valor de k consideras más conveniente y por qué?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c5ec393",
      "metadata": {
        "id": "3c5ec393"
      },
      "source": [
        "#### Hyperparameter tuning\n",
        "\n",
        "1. Implementa una búsqueda en rejilla con la función GridSearchCV de scikit-learn para encontrar el valor óptimo del parámetro k.\n",
        "2. Divide el conjunto de datos en entrenamiento y prueba.\n",
        "3. Realiza la búsqueda de hiperparámetros usando únicamente el conjunto de entrenamiento.\n",
        "4. Entrena el modelo con el valor óptimo de k que obtuviste en la búsqueda.\n",
        "5. Evalúa el modelo en el conjunto de prueba y reporta el error de generalización."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066d4e3f",
      "metadata": {
        "id": "066d4e3f"
      },
      "outputs": [],
      "source": [
        "# Tu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b26fdb8c",
      "metadata": {
        "id": "b26fdb8c"
      },
      "source": [
        "Edita las siguientes celdas para contestar las siguientes preguntas:\n",
        "\n",
        "1. ¿Cuál es el valor óptimo de k según la busqueda de rejilla?\n",
        "2. ¿Por qué es importante usar validación cruzada para encontrar el valor óptimo de k?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee7560ac",
      "metadata": {
        "id": "ee7560ac"
      },
      "source": [
        "# Ejemplos extras - utilizando otros tipos de regresores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5fbf7d9",
      "metadata": {
        "id": "a5fbf7d9"
      },
      "source": [
        "#### Regressor SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8b22102",
      "metadata": {
        "id": "f8b22102"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import learning_curve, cross_val_score\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Datos\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# Modelo real (pipeline con escalado + SVR)\n",
        "model = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVR(\n",
        "        kernel=\"rbf\",   # kernel RBF (gaussiano), puedes probar \"linear\" o \"poly\"\n",
        "        C=1.0,          # parámetro de regularización\n",
        "        epsilon=0.1     # margen de tolerancia en la regresión\n",
        "    )\n",
        ")\n",
        "\n",
        "# Curva de aprendizaje del modelo\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    model, X, y, cv=5, scoring=\"neg_mean_squared_error\",\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1\n",
        ")\n",
        "\n",
        "# Medias y desviaciones\n",
        "train_mean = -np.mean(train_scores, axis=1)\n",
        "train_std  = np.std(train_scores, axis=1)\n",
        "val_mean   = -np.mean(val_scores, axis=1)\n",
        "val_std    = np.std(val_scores, axis=1)\n",
        "\n",
        "# ======== Baselines ========\n",
        "\n",
        "# DummyRegressor con media\n",
        "dummy_mean = DummyRegressor(strategy=\"mean\")\n",
        "dummy_mean_scores = cross_val_score(dummy_mean, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "baseline_mean = -np.mean(dummy_mean_scores)\n",
        "\n",
        "# DummyRegressor con mediana\n",
        "dummy_median = DummyRegressor(strategy=\"median\")\n",
        "dummy_median_scores = cross_val_score(dummy_median, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "baseline_median = -np.mean(dummy_median_scores)\n",
        "\n",
        "# ======== Gráfica ========\n",
        "\n",
        "plt.plot(train_sizes, train_mean, label=\"Entrenamiento (SVR)\", color=\"blue\")\n",
        "plt.fill_between(train_sizes, train_mean-train_std, train_mean+train_std, alpha=0.2, color=\"blue\")\n",
        "\n",
        "plt.plot(train_sizes, val_mean, label=\"Validación (SVR)\", color=\"orange\")\n",
        "plt.fill_between(train_sizes, val_mean-val_std, val_mean+val_std, alpha=0.2, color=\"orange\")\n",
        "\n",
        "# Líneas horizontales de los baselines\n",
        "plt.axhline(y=baseline_mean, color=\"red\", linestyle=\"--\", label=\"Dummy (mean)\")\n",
        "plt.axhline(y=baseline_median, color=\"green\", linestyle=\"--\", label=\"Dummy (median)\")\n",
        "\n",
        "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Curva de aprendizaje con SVR y baselines\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d146a8ee",
      "metadata": {
        "id": "d146a8ee"
      },
      "source": [
        "Curva de validación para el parámetro C del SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a651bb6b",
      "metadata": {
        "id": "a651bb6b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Datos\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# Modelo: SVR (kernel lineal por simplicidad)\n",
        "model = SVR(kernel=\"linear\")\n",
        "\n",
        "# Rango de valores de C a probar\n",
        "param_range = np.logspace(-3, 5, 10)  # desde 0.001 hasta 1000\n",
        "\n",
        "# Curva de validación con MSE\n",
        "train_scores, val_scores = validation_curve(\n",
        "    model, X, y,\n",
        "    param_name=\"C\",\n",
        "    param_range=param_range,\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_squared_error\",  # usamos MSE\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Convertimos los valores (hacerlos positivos)\n",
        "train_mean = -np.mean(train_scores, axis=1)\n",
        "train_std  = np.std(train_scores, axis=1)\n",
        "val_mean   = -np.mean(val_scores, axis=1)\n",
        "val_std    = np.std(val_scores, axis=1)\n",
        "\n",
        "# ======== Gráfica ========\n",
        "plt.semilogx(param_range, train_mean, label=\"Entrenamiento (MSE)\", color=\"blue\")\n",
        "plt.fill_between(param_range, train_mean-train_std, train_mean+train_std, alpha=0.2, color=\"blue\")\n",
        "\n",
        "plt.semilogx(param_range, val_mean, label=\"Validación (MSE)\", color=\"orange\")\n",
        "plt.fill_between(param_range, val_mean-val_std, val_mean+val_std, alpha=0.2, color=\"orange\")\n",
        "\n",
        "plt.xlabel(\"C\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Curva de validación para SVR (kernel lineal)\")\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22b3b7df",
      "metadata": {
        "id": "22b3b7df"
      },
      "source": [
        "### Regresor HistGradientBoostingRegressor\n",
        "\n",
        "Ejemplo learning curve para un regresor del tipo HistGradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ee3d84",
      "metadata": {
        "id": "c0ee3d84"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import learning_curve, cross_val_score\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "# Datos\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# ===== Modelo con HistGradientBoosting =====\n",
        "model_hgb = HistGradientBoostingRegressor(\n",
        "    max_depth=5,        # profundidad máxima de los árboles   probar 5, 2\n",
        "    learning_rate=0.1,  # tasa de aprendizaje\n",
        "    max_iter=200,       # número de iteraciones (árboles)  probar 200, 100\n",
        "    random_state=0,\n",
        "    min_samples_leaf=30\n",
        ")\n",
        "\n",
        "# Curva de aprendizaje\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    model_hgb, X, y, cv=5, scoring=\"neg_mean_squared_error\",\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1\n",
        ")\n",
        "\n",
        "# Medias y desviaciones\n",
        "train_mean = -np.mean(train_scores, axis=1)\n",
        "train_std  = np.std(train_scores, axis=1)\n",
        "val_mean   = -np.mean(val_scores, axis=1)\n",
        "val_std    = np.std(val_scores, axis=1)\n",
        "\n",
        "# ======== Baselines ========\n",
        "dummy_mean = DummyRegressor(strategy=\"mean\")\n",
        "dummy_mean_scores = cross_val_score(dummy_mean, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "baseline_mean = -np.mean(dummy_mean_scores)\n",
        "\n",
        "dummy_median = DummyRegressor(strategy=\"median\")\n",
        "dummy_median_scores = cross_val_score(dummy_median, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "baseline_median = -np.mean(dummy_median_scores)\n",
        "\n",
        "# ======== Gráfica ========\n",
        "plt.plot(train_sizes, train_mean, label=\"Entrenamiento (HistGBR)\", color=\"blue\")\n",
        "plt.fill_between(train_sizes, train_mean-train_std, train_mean+train_std, alpha=0.2, color=\"blue\")\n",
        "\n",
        "plt.plot(train_sizes, val_mean, label=\"Validación (HistGBR)\", color=\"orange\")\n",
        "plt.fill_between(train_sizes, val_mean-val_std, val_mean+val_std, alpha=0.2, color=\"orange\")\n",
        "\n",
        "plt.axhline(y=baseline_mean, color=\"red\", linestyle=\"--\", label=\"Dummy (mean)\")\n",
        "plt.axhline(y=baseline_median, color=\"green\", linestyle=\"--\", label=\"Dummy (median)\")\n",
        "\n",
        "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Curva de aprendizaje con HistGradientBoostingRegressor\")\n",
        "plt.ylim(0, 7000)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ds",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}